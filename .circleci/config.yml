# validate this file using:
#   python -c "import sys, yaml, json; json.dump(yaml.load(sys.stdin), sys.stdout, indent=4)" < .circleci/config.yml > out.json
#
# this document makes use of yaml aliases and merging to attempt to keep it DRY - http://www.yaml.org/refcard.html
#
# the build matrix is the combinatoric result of [Py2, Py3] * [Production, Staging, etc...]

version: 2
iteration: 7
aliases:
  - &branch_cache_key 'v3-{{ checksum "Pipfile.lock" }}'
  - &build_dir build
  - &build_dir_glob build/*
  - &venv_dir build/.venv
  - &workspace
    at: ~/project

  - &environ
    BUILD_DIR: *build_dir
    PYTHONUNBUFFERED: true
    PIPENV_VENV_IN_PROJECT: true # instruct pipenv to build the venv in current working dir
    TESTRUNNER_DOCKER_IMAGE: 104059736540.dkr.ecr.us-west-2.amazonaws.com/mbed/sdk-testrunner:master
    TESTRUNNER_OUTPUT_DIR: rpc_results

  - &job_build_common
    steps:
    - checkout
    - restore_cache:
        keys: [*branch_cache_key]
    - run: sudo pip install pipenv
    - run: pipenv run python scripts/dvcs_version.py
    - run: pipenv install --dev --${PYVER}
    - run: pipenv install '-e .' --skip-lock
    - run: pipenv run python -c "import mbed_cloud; print(mbed_cloud.__version__)"
    - save_cache:
        key: *branch_cache_key
        paths:
          - ~/.cache/pip
    - persist_to_workspace:
        root: .
        paths:
          - ./*

  - &job_test_common
    steps:
      - checkout
      - restore_cache:
          keys: [*branch_cache_key]
      - run: sudo pip install pipenv awscli
      # FIXME:
      # unfortunately we must do the 'build' again here
      # as the machine executor isn't the same environment as docker
      # (e.g. python3.5 instead of 3.6.1)
      # and use of docker for the testing is fraught with peril
      # worst case ... we're not testing in the same environment we're releasing from >_>
      - run: pipenv run python scripts/dvcs_version.py
      - run: pipenv install --dev --${PYVER}
      - run: pipenv install '-e .' --skip-lock
      - run: pipenv run python -c "import mbed_cloud; print(mbed_cloud.__version__)"
      - run: |
              if [[ ${CLOUD_VERSION} == production ]]; then
                export MBED_CLOUD_API_HOST=${MBED_CLOUD_API_HOST_PROD};
                export MBED_CLOUD_API_KEY=${MBED_CLOUD_API_KEY_PROD};
                echo "environment variables swapped: ${CLOUD_VERSION}";
              fi
              if [[ ${CLOUD_VERSION} == os2 ]]; then
                export MBED_CLOUD_API_HOST=${MBED_CLOUD_API_HOST_OS2};
                export MBED_CLOUD_API_KEY=${MBED_CLOUD_API_KEY_OS2};
                echo "environment variables swapped: ${CLOUD_VERSION}";
              fi
              echo "{\"api_key\":\"$MBED_CLOUD_API_KEY\", \"host\":\"$MBED_CLOUD_API_HOST\"}" > .mbed_cloud_config.json
              login="$(aws ecr get-login --no-include-email)"
              ${login}
              docker pull ${TESTRUNNER_DOCKER_IMAGE}
              mkdir -p results
      - run:
          name: run all tests
          command: pipenv run pytest --tb=short --cov=mbed_cloud --cov-config=.coveragerc --cov-report=html --cov-report=xml --junitxml=results/unittests.xml --self-contained-html --html=results/unittests.html
          no_output_timeout: 15m
      - run: pipenv run python scripts/ci_summary.py --noblock
      - store_artifacts:
          path: results
      - store_artifacts:
          path: rpc_results
      - run: pipenv run codecov --file=results/coverage.xml -e PYVER,CLOUD_VERSION

  - &job_deploy_common
    steps:
      - attach_workspace:
          <<: *workspace
      - restore_cache:
          keys: [*branch_cache_key]
      - run: sudo pip install pipenv
      - run: pipenv install twine
      - run:
          name: Build the wheel
          command: pipenv run python setup.py bdist_wheel
      - run:
          name: Upload build to PyPI
          command: |
                  pipenv install twine
                  pipenv run python setup.py bdist_wheel
                  echo 'registering and deploying package to "${TWINE_REPOSITORY_URL}" (or default)'
                  ls dist
                  pipenv run twine upload dist/*

jobs:
  build_2:
    <<: *job_build_common
    environment:
      <<: *environ
      PYVER: two
    docker:
      - image: circleci/python:2.7.13

  build_3:
    <<: *job_build_common
    environment:
      <<: *environ
      PYVER: three
    docker:
      - image: circleci/python:3.6.1

  tpip_report:
    environment:
      <<: *environ
    docker:
      - image: circleci/python:3.6.1
    steps:
      - attach_workspace:
          <<: *workspace
      - restore_cache:
          keys: [*branch_cache_key]
      - run: sudo pip install pipenv
      - run: pipenv run python scripts/tpip.py python_tpip.csv
      - store_artifacts:
          path: python_tpip.csv

  docs_build:
    environment:
      <<: *environ
    docker:
      - image: circleci/python:3.6.1
    steps:
      - attach_workspace:
          <<: *workspace
      - restore_cache:
          keys: [*branch_cache_key]
      - run: sudo apt-get update
      - run: sudo apt-get install pandoc
      - run: sudo pip install pipenv
      - run: pipenv install readme_renderer
      - run:
          name: Build documentation
          command: pipenv run sphinx-build -a -b html -c docs/ docs/ built_docs
      - run:
          name: Validate README.rst
          command: pipenv run python setup.py check -r -s
      - persist_to_workspace:
          root: .
          paths:
            - built_docs
      - store_artifacts:
          path: built_docs

  docs_upload:
    environment:
      <<: *environ
    docker:
      - image: circleci/python:3.6.1
    steps:
      - attach_workspace:
          <<: *workspace
      - run: sudo pip install awscli
      - run:
          name: Upload docs to Amazon S3
          command: aws s3 sync --delete --cache-control max-age=3600 built_docs s3://mbed-cloud-sdk-python

  test_integration_2:
    <<: *job_test_common
    environment:
      <<: *environ
      CLOUD_VERSION: integration
      PYVER: two
    machine: true

  test_integration_3:
    <<: *job_test_common
    environment:
      <<: *environ
      CLOUD_VERSION: integration
      PYVER: three
    machine: true

  test_production_2:
    <<: *job_test_common
    environment:
      <<: *environ
      CLOUD_VERSION: production
      PYVER: two
    machine: true

  test_production_3:
    <<: *job_test_common
    environment:
      <<: *environ
      CLOUD_VERSION: production
      PYVER: three
    machine: true

  test_os2_2:
    <<: *job_test_common
    environment:
      <<: *environ
      CLOUD_VERSION: os2
      PYVER: two
    machine: true

  test_os2_3:
    <<: *job_test_common
    environment:
      <<: *environ
      CLOUD_VERSION: os2
      PYVER: three
    machine: true

  deploy_beta:
    <<: *job_deploy_common
    environment:
      <<: *environ
      TWINE_REPOSITORY_URL: https://test.pypi.org/legacy/
    docker:
      - image: circleci/python:3.6.1

  deploy_production:
    <<: *job_deploy_common
    environment:
      <<: *environ
    docker:
      - image: circleci/python:3.6.1

workflows:
  version: 2
  python_sdk_workflow:
    jobs:
      - build_2
      - build_3
      - test_integration_2:
          requires:
            - build_2
            - test_integration_3
      - test_integration_3:
          requires:
            - build_3
      - test_production_2:
          requires:
            - build_2
            - test_production_3
      - test_production_3:
          requires:
            - build_3
      - test_os2_2:
          requires:
            - build_2
            - test_os2_3
      - test_os2_3:
          requires:
            - build_3
      - docs_build:
          requires:
            - build_3
      - docs_upload:
          requires:
            - docs_build
          filters:
            branches:
              only: master
      - tpip_report:
          requires:
            - build_3
      - release_beta:
          type: approval
          requires:
            - test_os2_3
      - release_production:
          type: approval
          requires:
            # Ideally this 'release hold' would also include test_production_2
            #  but because CCI2 mixes up workflow with caching, this breaks
            - test_production_3
          filters:
            branches:
              only: production
      - deploy_beta:
          requires:
            - release_beta
      - deploy_production:
          requires:
            - release_production
